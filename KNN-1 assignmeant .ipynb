{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc461fd3-da1d-49ea-9d1f-ec3dd526197d",
   "metadata": {},
   "source": [
    "Q1. What is the KNN algorithm?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd0c5c83-8962-4d22-ba41-ffe672bfa245",
   "metadata": {},
   "source": [
    "a non-parametric, supervised learning classifier, which uses proximity to make classifications or predictions about the grouping of an individual data point."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a64cf3-1572-4392-955a-29b96a2f7cba",
   "metadata": {},
   "source": [
    "Q2. How do you choose the value of K in KNN?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9b94423-b607-4431-9841-bc317e83b437",
   "metadata": {},
   "source": [
    "The optimal K value usually found is the square root of N, where N is the total number of samples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d547f4ef-bed7-4045-bf4d-4b1062b1a6f8",
   "metadata": {},
   "source": [
    "Q3. What is the difference between KNN classifier and KNN regressor?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "998a816e-28ae-46f5-84dc-29ea74f24b1a",
   "metadata": {},
   "source": [
    "KNN regression tries to predict the value of the output variable by using a local average. \n",
    "\n",
    "KNN classification attempts to predict the class to which the output variable belong by computing the local probability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4cf5b6d-3844-4a3b-aae9-39f8aeddbf2f",
   "metadata": {},
   "source": [
    "Q4. How do you measure the performance of KNN?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a44755-fc21-4762-9d0c-739db15f3838",
   "metadata": {},
   "source": [
    " measuring the distances between the test sample and the training samples to determine the final classification output."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b39428d-8574-4851-b00c-9916447b2336",
   "metadata": {},
   "source": [
    "Q5. What is the curse of dimensionality in KNN?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55dce9b5-aa77-4e0b-8717-3dc5bc1a221a",
   "metadata": {},
   "source": [
    "a tongue in cheek way of stating that there's a ton of space in high-dimensional data sets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e29655-c405-4355-869e-18abfdca453f",
   "metadata": {},
   "source": [
    "Q6. How do you handle missing values in KNN?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b4978a-1405-49d1-84c9-1684787535ff",
   "metadata": {},
   "source": [
    "Each sample's missing values are imputed using the mean value of the 'k'-neighbors found in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca544b9-0497-4e38-982f-1dfc4cccb45f",
   "metadata": {},
   "source": [
    "Q7. Compare and contrast the performance of the KNN classifier and regressor. Which one is better for\n",
    "which type of problem?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae6a7e7-7b06-4609-a47d-6c08a1bd7a73",
   "metadata": {},
   "source": [
    "the classifier is used in situations where the response variable is categorical (qualitative), while the regressor is used in numerical situations (quantitative)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a1fb832-f693-499d-855d-b90ae7c79b3e",
   "metadata": {},
   "source": [
    "If there is some variable and categorical both are present in dataset than we use KN classifire , and KNN refressor is better for numerical dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c32f1d2-5edc-4df8-ba6b-80fc8a1b0381",
   "metadata": {},
   "source": [
    "Q8. What are the strengths and weaknesses of the KNN algorithm for classification and regression tasks,\n",
    "and how can these be addressed?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63160711-94f4-44b4-bf16-1fb2e73a004f",
   "metadata": {},
   "source": [
    "advantages - nonparametric architecture, simple and powerful, requires no traning time , it solve both type of problems dataset classifire and regressor.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cecc7db7-186d-49df-b2d1-bfd9779975cc",
   "metadata": {},
   "source": [
    "disadvantage - memory intensive, classification and estimation are slow."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9446c490-27bd-43fe-aace-3fe15d030641",
   "metadata": {},
   "source": [
    "Q9. What is the difference between Euclidean distance and Manhattan distance in KNN?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39cebcff-dbad-4ddd-b1d6-1f431133095d",
   "metadata": {},
   "source": [
    "Euclidean distance is the shortest path between source and destination which is a straight line"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae5759d-e6d6-41c8-846a-808684c120da",
   "metadata": {},
   "source": [
    " Manhattan distance is sum of all the real distances between source and destination."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "301f2a74-e356-43c6-a40e-7c94a1573aab",
   "metadata": {},
   "source": [
    "Q10. What is the role of feature scaling in KNN?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ddf2b3-1dfb-4dd2-b999-cebbfc503050",
   "metadata": {},
   "source": [
    "Feature scaling is essential for machine learning algorithms that calculate distances between data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
